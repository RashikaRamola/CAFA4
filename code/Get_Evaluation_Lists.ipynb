{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4a34777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import csv\n",
    "import io\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801a3dd7",
   "metadata": {},
   "source": [
    "extract_annot()\n",
    "Extracts the GO annotations from raw .gaf files. \n",
    "Removes duplicated, negative annotations, extract the annotations only with the given evidence codes\t\n",
    "\n",
    "- gaf_file: path of the .gaf file\n",
    "- evidence codes = [EXP, IPI, IDA, IMP, IGI, IEP, TAS, IC, HTP, HDA, HMP, HGI, HEP]: optional.\n",
    "Default: experimental + high throughput codes \n",
    "- ann_file: Path + name of the extrracted annotations file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f9d16260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dup_and_neg(Extracted_ann, remove_dup = True, remove_neg = True):\n",
    "    N = len(Extracted_ann)\n",
    "    print(N, \" Rows in the input file\")\n",
    "    if remove_dup:\n",
    "        Extracted_ann = Extracted_ann.drop_duplicates().copy()\n",
    "        print(N-len(Extracted_ann), \" duplicates dropped\")\n",
    "    if remove_neg:\n",
    "        Not_qualifier = Extracted_ann[\"Qualifier\"].apply(lambda x:\"NOT\" in x)\n",
    "        Extracted_ann = Extracted_ann[~Not_qualifier].copy()\n",
    "        print(sum(Not_qualifier), \" Not Qualifiers found\")\n",
    "    return Extracted_ann\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a63ec52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_evidence_codes(Extracted_ann, evidence_codes = ['EXP', 'IDA', 'IPI','IMP', 'IGI', 'IEP', 'TAS', 'IC'], highTP = False):\n",
    "    if highTP:\n",
    "        evidence_codes += ['HTP', 'HDA', 'HMP', 'HGI', 'HEP']\n",
    "        print(\"High Thoughput Evidence Code included\")\n",
    "    print(\"Included evidence codes are :\", evidence_codes)\n",
    "    evidence_True = Extracted_ann['Evidence Code'].isin(evidence_codes)\n",
    "    print(sum(evidence_True))\n",
    "    Filtered = Extracted_ann[evidence_True].copy() \n",
    "    return Filtered\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b866f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extracts columns in the extract_col_list from the goa_file and returns them as a Dataframe\n",
    "Ignores the lines that start with '!'\n",
    "\n",
    "Parameters:\n",
    "    - goa_file: The input GOA file name.\n",
    "    - extract_col_list: Names of the columns to be extracted. Default: ['DB Object ID', 'Qualifier','GO ID', 'Evidence Code', 'Aspect']\n",
    "    \n",
    "Returns Extract_ann dataframe of the extracted annotations\n",
    "\"\"\"\n",
    "\n",
    "def extract_annot(goa_file, extract_col_list = ['DB Object ID', 'Qualifier','GO ID', 'Evidence Code', 'Aspect']):\n",
    "    # Uniprot gaf file description: https://geneontology.org/docs/go-annotation-file-gaf-format-2.0/\n",
    "    # List of Gaf_cols in gaf-version 2.0, 2.1 and 2.2\n",
    "    Gaf_cols = ['DB', 'DB Object ID', 'DB Object Symbol', 'Qualifier', 'GO ID', 'DB:Reference (|DB:Reference)', \n",
    "                       'Evidence Code', 'With (or) From', 'Aspect', 'DB Object Name', 'DB Object Synonym (|Synonym)', 'DB Object Type', \n",
    "                       'Taxon(|taxon)', 'Date', 'Assigned By', 'Annotation Extension', 'Gene Product Form ID']\n",
    "    \n",
    "    \n",
    "    extract_col_ind = [Gaf_cols.index(col) for col in extract_col_list if col in Gaf_cols]\n",
    "    print(\"Indices of the extracted columns are : \", extract_col_ind)\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    with gzip.open(goa_file, 'rt') as f:\n",
    "        # Skip lines starting with '!'\n",
    "        filtered_lines = (line for line in f if not line.startswith('!'))\n",
    "        gaf_v = f.readline().strip().split(\" \")\n",
    "        \n",
    "        # Join the filtered lines into a single string\n",
    "        joined_lines = ''.join(filtered_lines)\n",
    "        \n",
    "        # Use StringIO to create a file-like object\n",
    "        file_like_object = io.StringIO(joined_lines)\n",
    "        \n",
    "        # Use csv.reader to parse TSV\n",
    "        tsv_reader = csv.reader(file_like_object, delimiter='\\t')\n",
    "        \n",
    "        # Iterate over the rows and extract specified columns\n",
    "        for row in tsv_reader:\n",
    "            extracted_row = [row[i] for i in extract_col_ind]\n",
    "            rows.append(extracted_row)\n",
    "    \n",
    "    # Create a DataFrame from the extracted rows\n",
    "    Extracted_ann = pd.DataFrame(rows, columns=extract_col_list)\n",
    "    \n",
    "    # Write DataFrame to CSV file\n",
    "    #df.to_csv(out_file, index=False)\n",
    "    \n",
    "    return Extracted_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfd71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_annot(Extracted_ann, out_file = \"extracted.tsv\"):\n",
    "    out_cols = ['DB Object ID', ]\n",
    "    Extracted_ann[:, ['DB Object ID', 'GO ID', 'Aspect']].to_csv(out_file, index = False, sep = \"\\t\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afb41da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser.add_argument(\"goa_path\", help=\"Path of the gaf.gz file\")\n",
    "    parser.add_argument(\"out_path\", help=\"Path of the extracted file\", default = \"extracted.tsv\")\n",
    "    parser.add_argument(\"-e\", \"--evidience codes\", help=\"List of the evidence codes to be included\", nargs = '+', default = \"EXP IDA IPI IMP IGI IEP TAS IC\")\n",
    "    parser.add_argument(\"--highTP\", help=\"Include high throughput evidence codes\", type=str2bool, nargs='?', default=False)\n",
    "    parser.add_argument('--enable', help='Enable something')\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    if args.out_path:\n",
    "        out_file = out_path\n",
    "    else:\n",
    "        out_file = \"extracted.csv\"\n",
    "    Extracted_annextract_annot(args.goa_path, out_file, extract_col_list = ['DB Object ID', 'Qualifier','GO ID', 'Evidence Code', 'Aspect'])\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "79d7b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_sample = \"/data/rashika/CAFA4/uniprot/caution/sample_t0.gz\"\n",
    "t1_sample = \"/data/rashika/CAFA4/uniprot/caution/sample_t1.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "dd2ed0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of the extracted columns are :  [1, 3, 4, 6, 8]\n",
      "Indices of the extracted columns are :  [1, 3, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "t0_df = extract_annot(t0_sample)\n",
    "t1_df = extract_annot(t1_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "afd5ee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9992  Rows\n",
      "2832  duplicates dropped\n",
      "0  Not Qualifiers found\n",
      "High Thoughput Evidence Code included\n",
      "Included evidence codes are : ['EXP', 'IDA', 'IPI', 'IMP', 'IGI', 'IEP', 'TAS', 'IC', 'HTP', 'HDA', 'HMP', 'HGI', 'HEP', 'HTP', 'HDA', 'HMP', 'HGI', 'HEP']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "Extracted_ann = remove_dup_and_neg(t0_df)\n",
    "f = filter_evidence_codes(Extracted_ann, highTP = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "0b2a00ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IEA'], dtype=object)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0_df[\"Evidence Code\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "48521b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "9984    False\n",
      "9985    False\n",
      "9986    False\n",
      "9987    False\n",
      "9990    False\n",
      "Name: Qualifier, Length: 7165, dtype: bool\n",
      "7165\n",
      "7165\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d959ced7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "867590ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DB Object ID</th>\n",
       "      <th>Qualifier</th>\n",
       "      <th>GO ID</th>\n",
       "      <th>Evidence Code</th>\n",
       "      <th>Aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>Q9WUC4</td>\n",
       "      <td>involved_in</td>\n",
       "      <td>GO:0006979</td>\n",
       "      <td>IDA</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>Q9WUC4</td>\n",
       "      <td>involved_in</td>\n",
       "      <td>GO:0043066</td>\n",
       "      <td>IDA</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>Q9WUC4</td>\n",
       "      <td>involved_in</td>\n",
       "      <td>GO:0060003</td>\n",
       "      <td>IMP</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>Q9WUC4</td>\n",
       "      <td>enables</td>\n",
       "      <td>GO:0051117</td>\n",
       "      <td>IPI</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>Q6DBW0</td>\n",
       "      <td>acts_upstream_of_or_within</td>\n",
       "      <td>GO:0071908</td>\n",
       "      <td>IMP</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5499</th>\n",
       "      <td>Q6DBW0</td>\n",
       "      <td>acts_upstream_of_or_within</td>\n",
       "      <td>GO:0035469</td>\n",
       "      <td>IMP</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5500</th>\n",
       "      <td>Q6DBW0</td>\n",
       "      <td>acts_upstream_of_or_within</td>\n",
       "      <td>GO:0003140</td>\n",
       "      <td>IMP</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5501</th>\n",
       "      <td>Q6DBW0</td>\n",
       "      <td>acts_upstream_of_or_within</td>\n",
       "      <td>GO:0007368</td>\n",
       "      <td>IMP</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8352</th>\n",
       "      <td>Q07627</td>\n",
       "      <td>located_in</td>\n",
       "      <td>GO:0005829</td>\n",
       "      <td>TAS</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8353</th>\n",
       "      <td>Q07627</td>\n",
       "      <td>enables</td>\n",
       "      <td>GO:0005515</td>\n",
       "      <td>IPI</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DB Object ID                   Qualifier       GO ID Evidence Code Aspect\n",
       "2973       Q9WUC4                 involved_in  GO:0006979           IDA      P\n",
       "2974       Q9WUC4                 involved_in  GO:0043066           IDA      P\n",
       "2981       Q9WUC4                 involved_in  GO:0060003           IMP      P\n",
       "2982       Q9WUC4                     enables  GO:0051117           IPI      F\n",
       "5497       Q6DBW0  acts_upstream_of_or_within  GO:0071908           IMP      P\n",
       "5499       Q6DBW0  acts_upstream_of_or_within  GO:0035469           IMP      P\n",
       "5500       Q6DBW0  acts_upstream_of_or_within  GO:0003140           IMP      P\n",
       "5501       Q6DBW0  acts_upstream_of_or_within  GO:0007368           IMP      P\n",
       "8352       Q07627                  located_in  GO:0005829           TAS      C\n",
       "8353       Q07627                     enables  GO:0005515           IPI      F"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde9cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_annot(goa_file, out_file=\"extracted.csv\", gaf_version = \"2.2\"):\n",
    "    \"\"\"\n",
    "    Extracts columns from a GOA file and writes them to a new file.\n",
    "\n",
    "    Parameters:\n",
    "    - goa_file: The input GOA file name.\n",
    "    - n_skip: No. of rows to be skipped. Default value 9.\n",
    "    - out_file: (Optional) The output file name. Defaults to 'extracted.csv'.\n",
    "    - col_list: List of column IDs to be extracted, e.g., [1, 5]. Defaults to [1, 4].\n",
    "    \"\"\"\n",
    "    with gzip.open(goa_file, 'rt') as f:\n",
    "        # Skip the first 8 lines\n",
    "        for _ in range(n_skip):\n",
    "            next(f)\n",
    "\n",
    "        # Create a CSV reader object with tab delimiter\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "\n",
    "        # Open the output file for writing\n",
    "        with open(out_file, 'w') as outfile:\n",
    "            # Create a CSV writer object\n",
    "            writer = csv.writer(outfile, delimiter='\\t')\n",
    "            \n",
    "            # Iterate over each row in the reader\n",
    "            for row in reader:\n",
    "                # Extract the specified columns\n",
    "                extracted_columns = [row[i] for i in col_list]\n",
    "\n",
    "                # Write the extracted columns to the output file\n",
    "                writer.writerow(extracted_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da0e544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16096ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94ab76a9",
   "metadata": {},
   "source": [
    "### Extract Entry ID, GO annotation, and ontology type from the gaf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d894b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output file paths\n",
    "t0_out_dir = '/data/rashika/CAFA4/uniprot/goa_2020_Jan_03/'\n",
    "t0_input_file = t0_out_dir + 'goa_uniprot_all.gaf.gz'\n",
    "t0_output_file = t0_out_dir + 'extracted_columns.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df22f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_col_list = [1,4, 8]\n",
    "n_skip = 8\n",
    "\n",
    "#extract_annot(t0_input_file, n_skip, t0_output_file, t0_col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f1809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output file paths\n",
    "t1_out_dir = '/data/rashika/CAFA4/uniprot/goa_2024-02-09/'\n",
    "t1_input_file = t1_out_dir + 'goa_uniprot_all.gaf.gz'\n",
    "t1_output_file = t1_out_dir + 'extracted_columns.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066f445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_col_list  = [1,3,4,6,8]\n",
    "n_skip = 9\n",
    "#extract_annot(t1_input_file, n_skip, t1_output_file, t1_col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fdc3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract annotations from the file used by Shawn\n",
    "shawn_t0_dir = '/data/yisupeng/sharing/cafa4/'\n",
    "in_file = shawn_t0_dir + 'goa_uniprot_all_02142020.gaf.gz'\n",
    "shawn_out_file = '/data/rashika/CAFA4/uniprot/'+ 'shawn_extracted_columns.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8963901",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list  = [1,4, 6, 8]\n",
    "n_skip = 8\n",
    "#extract_annot(in_file, n_skip, shawn_out_file, col_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a1527",
   "metadata": {},
   "source": [
    "### Map the Extracted annotations to the CAFA targets (by Entry ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88deb8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_goa_to_cafa_ids(file_path, mapping_file, primary_id_column, out_path, chunk_size=100000):\n",
    "    \"\"\"\n",
    "    Read a CSV file in chunks, map the primary ID to a mapping file, and keep the rows that can be mapped.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: Path to the CSV file.\n",
    "    - mapping_file: Path to the mapping file (CSV).\n",
    "    - primary_id_column: Name of the column containing the primary ID in the mapping file.\n",
    "    - out_path: Path to the output file.\n",
    "    - chunk_size: Size of each chunk. Defaults to 100,000 lines.\n",
    "    \"\"\"\n",
    "    # Read the mapping file into a DataFrame\n",
    "    mapping_df = pd.read_csv(mapping_file, sep = \",\", header = 0)\n",
    "    mapping_df.columns = [\"Entry\", \"CAFA4_ID\"]\n",
    "\n",
    "    # Extract the primary IDs from the mapping file and convert to a set for efficient lookup\n",
    "    id_set = set(mapping_df[\"Entry\"])\n",
    "\n",
    "    # Initialize an empty list to store filtered chunk dataframes\n",
    "    dfs = []\n",
    "\n",
    "    # Read the CSV file in chunks\n",
    "    #flag = 0\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunk_size, sep = \"\\t\"):\n",
    "        # Filter the chunk based on whether the primary ID can be found in the mapping file\n",
    "        filtered_chunk = chunk[chunk.iloc[:,primary_id_column].isin(id_set)]\n",
    "        filtered_chunk = filtered_chunk.drop_duplicates().copy()\n",
    "        dfs.append(filtered_chunk)\n",
    "        #print(chunk.iloc[:,primary_id_column])\n",
    "        #print(list(id_set)[:10])\n",
    "        #flag+=1\n",
    "        #if flag==100:\n",
    "        #    break\n",
    "\n",
    "    # Concatenate all the filtered chunk dataframes into a single dataframe\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Write the final dataframe to the output file\n",
    "    df.to_csv(out_path, index=False, sep = \"\\t\")\n",
    "\n",
    "# Example usage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "60228f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mapping_file = \"/data/rashika/CAFA4/CAFA4_gt/Target_Entry_map.csv\"\n",
    "\n",
    "#Mapping_df = pd.read_csv(Mapping_file,  sep = ',', header = None)\n",
    "#Mapping_df.columns = [\"Entry\", \"CAFA4_ID\"]\n",
    "\n",
    "t1_mapped_ann = \"/data/rashika/CAFA4/CAFA4_gt/t1_ann.csv\"\n",
    "t0_mapped_ann = \"/data/rashika/CAFA4/CAFA4_gt/t0_ann.csv\"\n",
    "shawn_t0_mapped_ann = \"/data/rashika/CAFA4/CAFA4_gt/shawn_t0_ann.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db763c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clara_Entry_IDs = \"/data/rashika/CAFA4/CAFA4_gt/Entry.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2d7ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clara_Entry_IDs = pd.read_csv(Clara_Entry_IDs,  sep = '\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9718d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mapping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0bfad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map t1 annotations\n",
    "#map_goa_to_cafa_ids(t1_output_file, Mapping_file, 0, t1_mapped_ann )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf454e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map t0 annotations\n",
    "#map_goa_to_cafa_ids(t0_output_file, Mapping_file, 0, t0_mapped_ann )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef03582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Shawn's annotations\n",
    "#map_goa_to_cafa_ids(shawn_out_file, Mapping_file, 0, shawn_t0_mapped_ann )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "57db1bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://geneontology.org/docs/guide-go-evidence-codes/\n",
    "#Exp_codes = ['EXP', 'IDA', 'IMP', 'IGI', 'IEP', 'TAS', 'IC' ]\n",
    "Evidence_codes = ['EXP', 'IDA', 'IPI','IMP', 'IGI', 'IEP', 'TAS', 'IC', 'HTP', 'HDA', 'HMP', 'HGI', 'HEP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c7673828",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.read_csv(t1_mapped_ann,  sep = '\\t', header = None)\n",
    "t1.columns = ['Entry', 'edge', 'term', \"E_code\", \"aspect\"]\n",
    "\n",
    "\n",
    "# TO do\n",
    "\n",
    "# Write function to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c2a11ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EXP', 'HDA', 'HEP', 'HGI', 'HMP', 'HTP', 'IBA', 'IC', 'IDA',\n",
       "       'IEA', 'IEP', 'IGC', 'IGI', 'IKR', 'IMP', 'IPI', 'ISA', 'ISM',\n",
       "       'ISO', 'ISS', 'NAS', 'ND', 'RCA', 'TAS'], dtype=object)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(t1.loc[:,\"E_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "78d6a0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NOT|acts_upstream_of', 'NOT|acts_upstream_of_or_within',\n",
       "       'NOT|acts_upstream_of_or_within_negative_effect',\n",
       "       'NOT|acts_upstream_of_or_within_positive_effect',\n",
       "       'NOT|colocalizes_with', 'NOT|contributes_to', 'NOT|enables',\n",
       "       'NOT|involved_in', 'NOT|is_active_in', 'NOT|located_in',\n",
       "       'NOT|part_of', 'acts_upstream_of',\n",
       "       'acts_upstream_of_negative_effect', 'acts_upstream_of_or_within',\n",
       "       'acts_upstream_of_or_within_negative_effect',\n",
       "       'acts_upstream_of_or_within_positive_effect',\n",
       "       'acts_upstream_of_positive_effect', 'colocalizes_with',\n",
       "       'contributes_to', 'enables', 'involved_in', 'is_active_in',\n",
       "       'located_in', 'part_of'], dtype=object)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(t1.edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a9b7b55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2711301061495732"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(t1.loc[:,\"E_code\"].isin(Evidence_codes))/len(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc04de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = t1[t1.loc[:,\"E_code\"].isin(Evidence_codes)].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e98e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "shawn_t0 = pd.read_csv(shawn_t0_mapped_ann,  sep = '\\t', header = None)\n",
    "shawn_t0.columns = ['Entry', 'term', 'E_code','aspect']\n",
    "shawn_t0 = shawn_t0[shawn_t0.loc[:,\"E_code\"].isin(Evidence_codes)].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(shawn_t0['Entry']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59937da",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(t1['Entry']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce24373",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_mapped = pd.merge(t1, Mapping_df, on='Entry', how='inner')\n",
    "t1_mapped\n",
    "t1_mapped = t1_mapped.loc[:, [\"CAFA4_ID\", \"term\", \"aspect\", \"edge\"]]\n",
    "t1_mapped.to_csv('/data/rashika/CAFA4/CAFA4_gt/t1_mapped.csv', sep = \"\\t\", index=False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66638325",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_mapped = pd.merge(shawn_t0, Mapping_df, on='Entry', how='inner')\n",
    "t0_mapped\n",
    "t0_mapped = t0_mapped.loc[:, [\"CAFA4_ID\", \"term\", \"aspect\"]]\n",
    "t0_mapped.to_csv('/data/rashika/CAFA4/CAFA4_gt/t0_mapped.csv', sep = \"\\t\",index=False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4592920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
